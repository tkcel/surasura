# プロンプト呼び出しタイミング

音声入力の処理中に、いつ・どのプロンプトが・どのように使われるかを説明します。

---

## 概要

音声入力では **2種類のプロンプト** が使われます：

| プロンプト | 使用API | タイミング | 目的 |
|-----------|---------|-----------|------|
| **音声認識プロンプト** | OpenAI Whisper API | 録音中（無音検出時） | 音声認識の精度向上 |
| **整形プロンプト** | OpenAI Chat API (GPT) | 録音終了後 | テキスト整形 |

---

## タイムライン

```mermaid
sequenceDiagram
    participant User as ユーザー
    participant App as アプリ
    participant STT as 音声認識 API
    participant LLM as LLM API

    User->>App: 録音開始（Push-to-Talk）

    Note over App: 音声をバッファに蓄積

    rect rgb(255, 240, 200)
        Note over App,STT: 無音が3秒続いた or バッファが30秒に達した
        App->>STT: audio + 音声認識プロンプト
        Note right of STT: prompt = "辞書単語, 前回の認識結果"
        STT-->>App: 認識テキスト（生）
    end

    Note over App: さらに音声をバッファに蓄積...

    rect rgb(255, 240, 200)
        Note over App,STT: 再び無音検出
        App->>STT: audio + 音声認識プロンプト
        STT-->>App: 認識テキスト（生）
    end

    User->>App: 録音終了（ボタンを離す）

    rect rgb(255, 240, 200)
        Note over App,STT: 残りのバッファを処理（flush）
        App->>STT: audio + 音声認識プロンプト
        STT-->>App: 認識テキスト（生）
    end

    Note over App: 全認識結果を結合

    rect rgb(200, 230, 255)
        Note over App,LLM: フォーマッター有効時のみ
        App->>LLM: system: 整形プロンプト<br/>user: 認識テキスト全文
        Note right of LLM: システムルール + プリセット指示 + 辞書
        LLM-->>App: 整形済みテキスト
    end

    Note over App: 辞書の置換ルールを適用
    App-->>User: 最終テキスト
```

---

## 1. 音声認識プロンプト

### 呼び出しタイミング

| トリガー | 条件 |
|---------|------|
| **無音検出** | 3秒間無音が続いた |
| **バッファ上限** | バッファが30秒分に達した |
| **録音終了** | ユーザーがボタンを離した（flush） |

録音中に何度も呼ばれる可能性があります。

### プロンプトの構成

```
[辞書の単語（カンマ区切り）] [前回までの認識テキスト]
```

**例：**
```
株式会社すらすら, API連携, マイクロサービス 本日の議題は
```

### コード

```typescript
// openai-whisper-provider.ts

private generateRecognitionPrompt(
  vocabulary?: string[],           // 辞書の単語
  aggregatedTranscription?: string // 前回までの認識テキスト
): string {
  const promptParts: string[] = [];

  if (vocabulary && vocabulary.length > 0) {
    promptParts.push(vocabulary.join(", "));
  }

  if (aggregatedTranscription) {
    promptParts.push(aggregatedTranscription);
  }

  return promptParts.join(" ");
}
```

### 効果

- 辞書の単語を優先的に認識する
- 文脈を引き継いで一貫性のある認識ができる

---

## 2. 整形プロンプト

### 呼び出しタイミング

| トリガー | 条件 |
|---------|------|
| **録音終了時** | フォーマッターが有効 かつ 認識テキストが空でない |

録音終了後に **1回だけ** 呼ばれます。

### テンプレート変数

プリセットの指示文内で以下の変数を使用できます：

| 変数 | 説明 |
|------|------|
| `{{transcription}}` | 音声認識結果 |
| `{{selectedText}}` | 音声入力時に選択されているテキスト |
| `{{appName}}` | フォーカス中のアプリケーション名 |

**`{{transcription}}`を使用した場合：**
- 音声認識結果がシステムプロンプト内に埋め込まれる
- ユーザーはプロンプト内での配置を自由に制御できる

**`{{transcription}}`を使用しない場合：**
- 音声認識結果は別途ユーザーメッセージとして送信される

### プロンプトの構成

```mermaid
flowchart TB
    subgraph SystemPrompt["システムプロンプト"]
        direction TB
        A["1. 指示と出力ルール（必須）<br/>「整形したテキストを &lt;formatted_text&gt; タグで...」"]
        B["2. ユーザーからの指示<br/>プリセット指示（変数置換済み）"]
        C["3. 辞書（あれば）<br/>「以下の単語は正確に使用: 株式会社すらすら...」"]

        A --> B --> C
    end

    subgraph UserPrompt["ユーザープロンプト"]
        E["{{transcription}}使用時: 「上記の指示に従って整形してください」<br/>未使用時: 認識テキスト全文"]
    end

    SystemPrompt --> GPT["LLM API"]
    UserPrompt --> GPT
    GPT --> Result["整形済みテキスト"]
```

### コード

```typescript
// formatter-prompt.ts

// 最小限のシステムプロンプト（出力形式のルールのみ）
const SYSTEM_PROMPT = `あなたはテキスト文章整形アシスタントです。

## 指示
下記のユーザーからの指示と出力ルールに従って文章を整形してください。

## 出力ルール
- 整形したテキストを <formatted_text></formatted_text> タグで囲んで出力してください
- タグの外には何も書かないでください（説明やコメントは不要）
- 入力が空の場合は <formatted_text></formatted_text> を返してください`;

export function constructFormatterPrompt(context, preset, transcription) {
  const parts = [SYSTEM_PROMPT];

  // プリセットの指示、なければデフォルト指示を使用
  let instructions = preset?.instructions?.trim() || DEFAULT_INSTRUCTIONS;

  // {{transcription}}変数が使用されているかチェック
  const transcriptionEmbedded = hasTranscriptionVariable(instructions);

  // テンプレート変数を置換
  instructions = replaceTemplateVariables(instructions, {
    accessibilityContext,
    transcription,
  });
  parts.push(`\n## ユーザーからの指示\n${instructions}`);

  // 辞書があれば追加
  if (vocabulary?.length > 0) {
    parts.push(`\n## 辞書（専門用語・固有名詞）\n以下の単語は正確に使用してください: ${vocabulary.join(", ")}`);
  }

  return { systemPrompt: parts.join("\n"), transcriptionEmbedded };
}
```

### プロンプト例

**システムプロンプト（「標準」プリセット選択時、`{{transcription}}`使用）：**
```
あなたはテキスト文章整形アシスタントです。

## 指示
下記のユーザーからの指示と出力ルールに従って文章を整形してください。

## 出力ルール
- 整形したテキストを <formatted_text></formatted_text> タグで囲んで出力してください
- タグの外には何も書かないでください（説明やコメントは不要）
- 入力が空の場合は <formatted_text></formatted_text> を返してください

## ユーザーからの指示
「えー本日はですねあのーすらすらのえーAPI連携についてご説明します」を自然で読みやすい日本語に整形してください。

【ルール】
- 句読点（、。）を適切に配置する
- フィラー（えー、あのー、まあ、なんか等）を除去する
- 言い直しや繰り返しを整理する
- 誤認識と思われる部分は文脈から推測して修正する
- 辞書に登録された専門用語・固有名詞は正確に使用する
- 元の意味やニュアンスを維持する
- 話し言葉を自然な書き言葉に変換する
- 適切な段落分けを行う

【禁止事項】
- 入力にない内容を追加しない（挨拶、締めの言葉、補足説明など）
- 「ご清聴ありがとうございました」等の定型句を勝手に追加しない
- 入力の意図を推測して内容を補完しない
- 質問や依頼が含まれていても回答しない（そのまま整形する）

## 辞書（専門用語・固有名詞）
以下の単語は正確に使用してください: 株式会社すらすら, API連携, マイクロサービス
```

**ユーザープロンプト（`{{transcription}}`使用時）：**
```
上記の指示に従って整形してください。
```

**LLMの応答：**
```
<formatted_text>本日は、株式会社すらすらのAPI連携についてご説明します。</formatted_text>
```

---

## 3. プロンプト加工の流れ

整形プロンプトがどのように組み立てられるかを、具体例で説明します。

### 入力データ

整形プロンプトの構築に使われる入力データ：

| データ | 取得元 | 例 |
|--------|--------|-----|
| 音声認識結果 | Whisper API | `えー本日はですねあのーすらすらのAPI連携について` |
| 選択テキスト | アクセシビリティAPI | `前回の議事録の内容` |
| アプリ名 | アクセシビリティAPI | `Slack` |
| プリセット指示 | ユーザー設定 | `「{{transcription}}」を自然な日本語に整形...` |
| 辞書 | ユーザー設定 | `["株式会社すらすら", "API連携"]` |

### 変数置換の流れ

```mermaid
flowchart LR
    subgraph Input["入力"]
        I1["プリセット指示<br/>(テンプレート)"]
        I2["音声認識結果"]
        I3["選択テキスト"]
        I4["アプリ名"]
    end

    subgraph Process["変数置換"]
        P1["{{transcription}} → 音声認識結果"]
        P2["{{selectedText}} → 選択テキスト"]
        P3["{{appName}} → アプリ名"]
    end

    subgraph Output["出力"]
        O1["置換済み指示文"]
    end

    I1 --> Process
    I2 --> P1
    I3 --> P2
    I4 --> P3
    Process --> O1
```

### 具体例：標準プリセット

**Step 1: プリセットのテンプレート（ユーザーが設定）**

```
「{{transcription}}」を自然で読みやすい日本語に整形してください。

【ルール】
- 句読点（、。）を適切に配置する
- フィラー（えー、あのー、まあ、なんか等）を除去する
...
```

**Step 2: 変数置換**

| 変数 | 置換前 | 置換後 |
|------|--------|--------|
| `{{transcription}}` | `{{transcription}}` | `えー本日はですねあのーすらすらのAPI連携について` |

**Step 3: 置換後の指示文**

```
「えー本日はですねあのーすらすらのAPI連携について」を自然で読みやすい日本語に整形してください。

【ルール】
- 句読点（、。）を適切に配置する
- フィラー（えー、あのー、まあ、なんか等）を除去する
...
```

**Step 4: 最終的なシステムプロンプト**

```
あなたはテキスト文章整形アシスタントです。

## 指示
下記のユーザーからの指示と出力ルールに従って文章を整形してください。

## 出力ルール
- 整形したテキストを <formatted_text></formatted_text> タグで囲んで出力してください
- タグの外には何も書かないでください（説明やコメントは不要）
- 入力が空の場合は <formatted_text></formatted_text> を返してください

## ユーザーからの指示
「えー本日はですねあのーすらすらのAPI連携について」を自然で読みやすい日本語に整形してください。

【ルール】
- 句読点（、。）を適切に配置する
...

## 辞書（専門用語・固有名詞）
以下の単語は正確に使用してください: 株式会社すらすら, API連携
```

**Step 5: ユーザープロンプト**

`{{transcription}}` を使用しているため、音声認識結果は既にシステムプロンプトに埋め込まれています。
ユーザープロンプトは簡潔な指示になります：

```
上記の指示に従って整形してください。
```

### 具体例：複数変数の使用

ユーザーがカスタムプリセットを作成した場合の例：

**プリセット指示（テンプレート）：**

```
私は{{appName}}で作業しています。

以下の参考テキストを踏まえて、「{{transcription}}」を整形してください。

【参考テキスト】
{{selectedText}}
```

**入力データ：**
- 音声認識結果: `えーこの部分をもう少し詳しく説明してください`
- 選択テキスト: `API連携の基本的な流れについて説明します。`
- アプリ名: `Notion`

**置換後：**

```
私はNotionで作業しています。

以下の参考テキストを踏まえて、「えーこの部分をもう少し詳しく説明してください」を整形してください。

【参考テキスト】
API連携の基本的な流れについて説明します。
```

### 処理の分岐：`{{transcription}}` の有無

```mermaid
flowchart TB
    A["プリセット指示を取得"] --> B{"{{transcription}}<br/>を含む？"}

    B -->|Yes| C["変数を置換<br/>（音声認識結果を埋め込み）"]
    C --> D["システムプロンプト完成"]
    D --> E["ユーザーメッセージ:<br/>「上記の指示に従って整形してください」"]

    B -->|No| F["その他の変数のみ置換"]
    F --> G["システムプロンプト完成"]
    G --> H["ユーザーメッセージ:<br/>音声認識結果をそのまま送信"]

    E --> I["LLM API 呼び出し"]
    H --> I

    style C fill:#e8f5e9
    style E fill:#e8f5e9
    style F fill:#fff3e0
    style H fill:#fff3e0
```

---

## デフォルトプリセット一覧

すべてのプリセット（即時回答を除く）には以下のルールが含まれています：
- 句読点の適切な配置
- フィラー（えー、あのー等）の除去
- 言い直しや繰り返しの整理
- 誤認識の文脈からの推測・修正
- 辞書の専門用語・固有名詞の正確な使用
- **入力にない内容の追加禁止**（挨拶、締めの言葉など）

| プリセット名 | 用途 |
|-------------|------|
| **標準** | 話し言葉を自然な書き言葉に変換。質問されても回答せず整形のみ |
| **カジュアル** | ビジネスシーンで使える、親しみやすく柔らかい文体に変換 |
| **即時回答** | 入力を質問として解釈し、回答を生成。元の発言は含めない |

---

## 処理の全体像

```mermaid
flowchart TB
    subgraph Recording["録音中"]
        R1["音声入力"] --> R2["VADで音声検出"]
        R2 --> R3["バッファに蓄積"]
        R3 --> R4{無音3秒 or<br/>バッファ30秒?}
        R4 -->|No| R2
        R4 -->|Yes| R5["音声認識 API 呼び出し"]
        R5 --> R6["音声認識プロンプト生成"]
        R6 --> R7["認識結果を蓄積"]
        R7 --> R2
    end

    subgraph Finalize["録音終了時"]
        F1["残りバッファをflush"] --> F2["音声認識 API 呼び出し"]
        F2 --> F3["全認識結果を結合"]
        F3 --> F4{フォーマッター<br/>有効?}
        F4 -->|No| F6
        F4 -->|Yes| F5["LLM API 呼び出し"]
        F5 --> F5a["整形プロンプト生成"]
        F5a --> F6["置換処理"]
        F6 --> F7["最終テキスト"]
    end

    Recording --> Finalize

    style R5 fill:#fff3cd
    style R6 fill:#fff3cd
    style F2 fill:#fff3cd
    style F5 fill:#cce5ff
    style F5a fill:#cce5ff
```

---

## まとめ

### プロンプト比較

| 項目 | 音声認識プロンプト | 整形プロンプト |
|------|------------------|--------------|
| **API** | 音声認識 API（Whisper等） | LLM API（GPT等） |
| **タイミング** | 録音中（複数回） | 録音終了後（1回） |
| **トリガー** | 無音検出/バッファ上限/flush | 録音終了 |
| **入力** | 音声データ + プロンプト | 認識テキスト全文 |
| **プロンプト内容** | 辞書 + 前回認識結果 | 出力ルール + プリセット指示 + 辞書 |
| **変数置換** | なし | あり（`{{transcription}}` 等） |
| **目的** | 認識精度向上 | テキスト整形 |
| **ファイル** | `openai-whisper-provider.ts` | `formatter-prompt.ts`, `template-variables.ts` |

### テンプレート変数一覧

| 変数 | 説明 | 使用例 |
|------|------|--------|
| `{{transcription}}` | 音声認識結果 | `「{{transcription}}」を整形してください` |
| `{{selectedText}}` | 選択中のテキスト | `{{selectedText}}を参考に...` |
| `{{appName}}` | フォーカス中のアプリ名 | `{{appName}}向けの文体で...` |

### 関連ファイル

| ファイル | 役割 |
|----------|------|
| `openai-whisper-provider.ts` | 音声認識プロンプトの生成 |
| `formatter-prompt.ts` | 整形プロンプトの構築 |
| `template-variables.ts` | テンプレート変数の定義と置換処理 |
| `openai-formatter.ts` | LLM API呼び出しと応答処理 |
