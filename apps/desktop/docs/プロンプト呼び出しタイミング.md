# プロンプト呼び出しタイミング

音声入力の処理中に、いつ・どのプロンプトが・どのように使われるかを説明します。

---

## 概要

音声入力では **2種類のプロンプト** が使われます：

| プロンプト | 使用API | タイミング | 目的 |
|-----------|---------|-----------|------|
| **音声認識プロンプト** | OpenAI Whisper API | 録音中（無音検出時） | 音声認識の精度向上 |
| **整形プロンプト** | OpenAI Chat API (GPT) | 録音終了後 | テキスト整形 |

---

## タイムライン

```mermaid
sequenceDiagram
    participant User as ユーザー
    participant App as アプリ
    participant STT as 音声認識 API
    participant LLM as LLM API

    User->>App: 録音開始（Push-to-Talk）

    Note over App: 音声をバッファに蓄積

    rect rgb(255, 240, 200)
        Note over App,STT: 無音が3秒続いた or バッファが30秒に達した
        App->>STT: audio + 音声認識プロンプト
        Note right of STT: prompt = "辞書単語, 前回の認識結果"
        STT-->>App: 認識テキスト（生）
    end

    Note over App: さらに音声をバッファに蓄積...

    rect rgb(255, 240, 200)
        Note over App,STT: 再び無音検出
        App->>STT: audio + 音声認識プロンプト
        STT-->>App: 認識テキスト（生）
    end

    User->>App: 録音終了（ボタンを離す）

    rect rgb(255, 240, 200)
        Note over App,STT: 残りのバッファを処理（flush）
        App->>STT: audio + 音声認識プロンプト
        STT-->>App: 認識テキスト（生）
    end

    Note over App: 全認識結果を結合

    rect rgb(200, 230, 255)
        Note over App,LLM: フォーマッター有効時のみ
        App->>LLM: system: 整形プロンプト<br/>user: 認識テキスト全文
        Note right of LLM: システムルール + プリセット指示 + 辞書
        LLM-->>App: 整形済みテキスト
    end

    Note over App: 辞書の置換ルールを適用
    App-->>User: 最終テキスト
```

---

## 1. 音声認識プロンプト

### 呼び出しタイミング

| トリガー | 条件 |
|---------|------|
| **無音検出** | 3秒間無音が続いた |
| **バッファ上限** | バッファが30秒分に達した |
| **録音終了** | ユーザーがボタンを離した（flush） |

録音中に何度も呼ばれる可能性があります。

### プロンプトの構成

```
[辞書の単語（カンマ区切り）] [前回までの認識テキスト]
```

**例：**
```
株式会社すらすら, API連携, マイクロサービス 本日の議題は
```

### コード

```typescript
// openai-whisper-provider.ts

private generateRecognitionPrompt(
  vocabulary?: string[],           // 辞書の単語
  aggregatedTranscription?: string // 前回までの認識テキスト
): string {
  const promptParts: string[] = [];

  if (vocabulary && vocabulary.length > 0) {
    promptParts.push(vocabulary.join(", "));
  }

  if (aggregatedTranscription) {
    promptParts.push(aggregatedTranscription);
  }

  return promptParts.join(" ");
}
```

### 効果

- 辞書の単語を優先的に認識する
- 文脈を引き継いで一貫性のある認識ができる

---

## 2. 整形プロンプト

### 呼び出しタイミング

| トリガー | 条件 |
|---------|------|
| **録音終了時** | フォーマッターが有効 かつ 認識テキストが空でない |

録音終了後に **1回だけ** 呼ばれます。

### プロンプトの構成

```mermaid
flowchart TB
    subgraph SystemPrompt["システムプロンプト"]
        direction TB
        A["1. 出力ルール（必須）<br/>「整形したテキストを &lt;formatted_text&gt; タグで...」"]
        B["2. 整形ルール<br/>プリセット指示 or デフォルト指示"]
        C["3. 辞書（あれば）<br/>「以下の単語は正確に使用: 株式会社すらすら...」"]

        A --> B --> C
    end

    subgraph UserPrompt["ユーザープロンプト"]
        E["認識テキスト全文<br/>「えー本日はですねあのーすらすらの...」"]
    end

    SystemPrompt --> GPT["LLM API"]
    UserPrompt --> GPT
    GPT --> Result["整形済みテキスト"]
```

### コード

```typescript
// formatter-prompt.ts

// 最小限のシステムプロンプト（出力形式のルールのみ）
const SYSTEM_PROMPT = `あなたはテキスト整形アシスタントです。

## 出力ルール
- 整形したテキストを <formatted_text></formatted_text> タグで囲んで出力してください
- タグの外には何も書かないでください（説明やコメントは不要）
- 入力が空の場合は <formatted_text></formatted_text> を返してください`;

export function constructFormatterPrompt(context, preset) {
  const parts = [SYSTEM_PROMPT];

  // プリセットの指示、なければデフォルト指示を使用
  const instructions = preset?.instructions?.trim() || DEFAULT_INSTRUCTIONS;
  parts.push(`\n## 整形ルール\n${instructions}`);

  // 辞書があれば追加
  if (vocabulary?.length > 0) {
    parts.push(`\n## 辞書（専門用語・固有名詞）\n以下の単語は正確に使用してください: ${vocabulary.join(", ")}`);
  }

  return { systemPrompt: parts.join("\n") };
}
```

### プロンプト例

**システムプロンプト（「標準」プリセット選択時）：**
```
あなたはテキスト整形アシスタントです。

## 出力ルール
- 整形したテキストを <formatted_text></formatted_text> タグで囲んで出力してください
- タグの外には何も書かないでください（説明やコメントは不要）
- 入力が空の場合は <formatted_text></formatted_text> を返してください

## 整形ルール
音声認識結果を自然で読みやすい日本語に整形してください。

【基本ルール】
- 句読点（、。）を適切に配置する
- フィラー（えー、あのー、まあ、なんか等）を除去する
- 言い直しや繰り返しを整理する
- 誤認識と思われる部分は文脈から推測して修正する
- 辞書に登録された専門用語・固有名詞は正確に使用する
- 元の意味やニュアンスを維持する

【禁止事項】
- 入力にない内容を追加しない（挨拶、締めの言葉、補足説明など）
- 「ご清聴ありがとうございました」等の定型句を勝手に追加しない
- 入力の意図を推測して内容を補完しない

【このプリセット固有のルール】
- 話し言葉を自然な書き言葉に変換する
- 適切な段落分けを行う
- 質問や依頼の内容が含まれていても、回答せずにそのまま整形する

## 辞書（専門用語・固有名詞）
以下の単語は正確に使用してください: 株式会社すらすら, API連携, マイクロサービス
```

**ユーザープロンプト：**
```
えー本日はですねあのーすらすらのえーAPI連携についてご説明します
```

**LLMの応答：**
```
<formatted_text>本日は、株式会社すらすらのAPI連携についてご説明します。</formatted_text>
```

---

## デフォルトプリセット一覧

すべてのプリセット（即時回答を除く）には以下の基本ルールが含まれています：
- 句読点の適切な配置
- フィラー（えー、あのー等）の除去
- 言い直しや繰り返しの整理
- 誤認識の文脈からの推測・修正
- 辞書の専門用語・固有名詞の正確な使用
- **入力にない内容の追加禁止**（挨拶、締めの言葉など）

| プリセット名 | 用途 |
|-------------|------|
| **標準** | 話し言葉を自然な書き言葉に変換。質問されても回答せず整形のみ |
| **カジュアル** | 敬語を使わず、友達に話すようなくだけた口調に変換 |
| **Markdown** | 見出し・箇条書き・太字などで構造化。技術文書に最適 |
| **即時回答** | 入力を質問として解釈し、回答を生成。元の発言は含めない |

---

## 処理の全体像

```mermaid
flowchart TB
    subgraph Recording["録音中"]
        R1["音声入力"] --> R2["VADで音声検出"]
        R2 --> R3["バッファに蓄積"]
        R3 --> R4{無音3秒 or<br/>バッファ30秒?}
        R4 -->|No| R2
        R4 -->|Yes| R5["音声認識 API 呼び出し"]
        R5 --> R6["音声認識プロンプト生成"]
        R6 --> R7["認識結果を蓄積"]
        R7 --> R2
    end

    subgraph Finalize["録音終了時"]
        F1["残りバッファをflush"] --> F2["音声認識 API 呼び出し"]
        F2 --> F3["全認識結果を結合"]
        F3 --> F4{フォーマッター<br/>有効?}
        F4 -->|No| F6
        F4 -->|Yes| F5["LLM API 呼び出し"]
        F5 --> F5a["整形プロンプト生成"]
        F5a --> F6["置換処理"]
        F6 --> F7["最終テキスト"]
    end

    Recording --> Finalize

    style R5 fill:#fff3cd
    style R6 fill:#fff3cd
    style F2 fill:#fff3cd
    style F5 fill:#cce5ff
    style F5a fill:#cce5ff
```

---

## まとめ

| 項目 | 音声認識プロンプト | 整形プロンプト |
|------|------------------|--------------|
| **API** | 音声認識 API（Whisper等） | LLM API（GPT等） |
| **タイミング** | 録音中（複数回） | 録音終了後（1回） |
| **トリガー** | 無音検出/バッファ上限/flush | 録音終了 |
| **入力** | 音声データ + プロンプト | 認識テキスト全文 |
| **プロンプト内容** | 辞書 + 前回認識結果 | 出力ルール + プリセット指示 + 辞書 |
| **目的** | 認識精度向上 | テキスト整形 |
| **ファイル** | `openai-whisper-provider.ts` | `formatter-prompt.ts` |
